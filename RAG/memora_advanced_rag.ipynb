{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "from operator import itemgetter\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import (\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    SentenceTransformersTokenTextSplitter,\n",
    ")\n",
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n",
    "from helper_utils import project_embeddings, word_wrap\n",
    "from pypdf import PdfReader\n",
    "\n",
    "import fitz  # PyMuPDF library for PDF manipulation\n",
    "import re\n",
    "import unicodedata\n",
    "from langchain_community.document_loaders import (\n",
    "    PyPDFLoader,\n",
    "    Docx2txtLoader,\n",
    "    UnstructuredWordDocumentLoader,\n",
    "    UnstructuredExcelLoader,\n",
    "    UnstructuredPowerPointLoader,\n",
    "    UnstructuredImageLoader,\n",
    "    UnstructuredHTMLLoader,\n",
    ")\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "MODEL = \"llama3\"\n",
    "\n",
    "model = Ollama(model=MODEL)\n",
    "embeddings = OllamaEmbeddings(model=MODEL)\n",
    "\n",
    "parser = StrOutputParser()\n",
    "chain = model | parser\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    return unicodedata.normalize(\"NFKD\", text).encode(\"ASCII\", \"ignore\").decode(\"ASCII\")\n",
    "\n",
    "\n",
    "def load_documents(file_paths):\n",
    "    documents = []\n",
    "    for file_path in file_paths:\n",
    "        _, file_extension = os.path.splitext(file_path.lower())\n",
    "        if file_extension == \".pdf\":\n",
    "            loader = PyPDFLoader(file_path)\n",
    "        elif file_extension in [\".doc\", \".docx\", \".odt\"]:\n",
    "            loader = Docx2txtLoader(file_path)\n",
    "        elif file_extension in [\".rtf\", \".txt\"]:\n",
    "            loader = UnstructuredWordDocumentLoader(file_path)\n",
    "        elif file_extension in [\".xls\", \".xlsx\", \".ods\", \".csv\"]:\n",
    "            loader = UnstructuredExcelLoader(file_path)\n",
    "        elif file_extension in [\".ppt\", \".pptx\", \".odp\"]:\n",
    "            loader = UnstructuredPowerPointLoader(file_path)\n",
    "        elif file_extension in [\n",
    "            \".bmp\",\n",
    "            \".gif\",\n",
    "            \".jpg\",\n",
    "            \".jpeg\",\n",
    "            \".png\",\n",
    "            \".svg\",\n",
    "            \".tiff\",\n",
    "        ]:\n",
    "            loader = UnstructuredImageLoader(file_path)\n",
    "        elif file_extension == \".html\":\n",
    "            loader = UnstructuredHTMLLoader(file_path)\n",
    "        else:\n",
    "            print(f\"Unsupported file format: {file_extension}\")\n",
    "            continue\n",
    "\n",
    "        documents.extend(loader.load())\n",
    "\n",
    "    return documents\n",
    "\n",
    "\n",
    "def extract_highlighted_text(pdf_path, page_num, start_char, end_char):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    page = doc[page_num]\n",
    "\n",
    "    # Get the rectangle coordinates for the text range\n",
    "    start_rect = page.get_text(\"words\")[start_char][:4]\n",
    "    end_rect = page.get_text(\"words\")[end_char - 1][:4]\n",
    "\n",
    "    # Create a rectangle that encompasses the text range\n",
    "    highlight_rect = fitz.Rect(start_rect[0], start_rect[1], end_rect[2], end_rect[3])\n",
    "\n",
    "    # Extract the text within the rectangle\n",
    "    highlighted_text = page.get_text(\"text\", clip=highlight_rect)\n",
    "\n",
    "    # Optionally, you can still add a highlight annotation if needed\n",
    "    # page.add_highlight_annot(highlight_rect)\n",
    "\n",
    "    doc.close()\n",
    "    return highlighted_text\n",
    "\n",
    "\n",
    "def create_citation(document, relevant_text):\n",
    "    return {\n",
    "        \"document_name\": document.metadata.get(\"source\", \"Unknown\"),\n",
    "        \"page_number\": document.metadata.get(\"page\", 0) + 1,\n",
    "        \"text\": relevant_text,\n",
    "        \"start_char\": document.page_content.index(relevant_text),\n",
    "        \"end_char\": document.page_content.index(relevant_text) + len(relevant_text),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and split documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hoangvmdeptrai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "c:\\Users\\hoangvmdeptrai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "must perform a collection in order to free some memory. · error handling — thanks to th\n",
      "e jit compiler,. net platform can support easy error handling in your application code.\n",
      " when an error occurs, instead of terminate the process the clr throw error event. · th\n",
      "read management — in the. net platform, the clr is responsible for allocate resources f\n",
      "or running applications. in particular, the clr thread pool determines when threads are\n",
      " to be added or taken away. · performance optimization — when converting the cil code t\n",
      "o native code the jit compiler optimizes the code for the machine platform and cpu, and\n",
      " therefore the application performance improved. conclusion\n",
      "\n",
      "Total chunks: 17\n"
     ]
    }
   ],
   "source": [
    "reader = PdfReader(\"dotnet.pdf\")\n",
    "pdf_texts = [p.extract_text().strip() for p in reader.pages]\n",
    "# print(\n",
    "#     word_wrap(\n",
    "#         pdf_texts[0],\n",
    "#         width=100,\n",
    "#     )\n",
    "# )\n",
    "character_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"], chunk_size=1000, chunk_overlap=0\n",
    ")\n",
    "character_split_texts = character_splitter.split_text(\"\\n\\n\".join(pdf_texts))\n",
    "\n",
    "token_splitter = SentenceTransformersTokenTextSplitter(\n",
    "    chunk_overlap=0, tokens_per_chunk=256\n",
    ")\n",
    "\n",
    "token_split_texts = []\n",
    "for text in character_split_texts:\n",
    "    token_split_texts += token_splitter.split_text(text)\n",
    "    \n",
    "print(word_wrap(token_split_texts[10]))\n",
    "print(f\"\\nTotal chunks: {len(token_split_texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "UniqueConstraintError",
     "evalue": "Collection microsoft-collection already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUniqueConstraintError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# print(embedding_function([token_split_texts[10]]))\u001b[39;00m\n\u001b[0;32m      4\u001b[0m chroma_client \u001b[38;5;241m=\u001b[39m chromadb\u001b[38;5;241m.\u001b[39mClient()\n\u001b[1;32m----> 5\u001b[0m chroma_collection \u001b[38;5;241m=\u001b[39m \u001b[43mchroma_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmicrosoft-collection\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_function\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# extract the embeddings of the token_split_texts\u001b[39;00m\n\u001b[0;32m     10\u001b[0m ids \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(token_split_texts))]\n",
      "File \u001b[1;32mc:\\Users\\hoangvmdeptrai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\chromadb\\api\\client.py:117\u001b[0m, in \u001b[0;36mClient.create_collection\u001b[1;34m(self, name, configuration, metadata, embedding_function, data_loader, get_or_create)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_collection\u001b[39m(\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    115\u001b[0m     get_or_create: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    116\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Collection:\n\u001b[1;32m--> 117\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_server\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtenant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mget_or_create\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_or_create\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfiguration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfiguration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Collection(\n\u001b[0;32m    126\u001b[0m         client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_server,\n\u001b[0;32m    127\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m    128\u001b[0m         embedding_function\u001b[38;5;241m=\u001b[39membedding_function,\n\u001b[0;32m    129\u001b[0m         data_loader\u001b[38;5;241m=\u001b[39mdata_loader,\n\u001b[0;32m    130\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\hoangvmdeptrai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\chromadb\\telemetry\\opentelemetry\\__init__.py:146\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[1;32m--> 146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\hoangvmdeptrai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\chromadb\\api\\segment.py:176\u001b[0m, in \u001b[0;36mSegmentAPI.create_collection\u001b[1;34m(self, name, configuration, metadata, get_or_create, tenant, database)\u001b[0m\n\u001b[0;32m    164\u001b[0m model \u001b[38;5;241m=\u001b[39m CollectionModel(\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mid\u001b[39m,\n\u001b[0;32m    166\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    173\u001b[0m     dimension\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    174\u001b[0m )\n\u001b[0;32m    175\u001b[0m \u001b[38;5;66;03m# TODO: Let sysdb create the collection directly from the model\u001b[39;00m\n\u001b[1;32m--> 176\u001b[0m coll, created \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sysdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfiguration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_configuration\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdimension\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# This is lazily populated on the first add\u001b[39;49;00m\n\u001b[0;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mget_or_create\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_or_create\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtenant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;66;03m# TODO: wrap sysdb call in try except and log error if it fails\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created:\n",
      "File \u001b[1;32mc:\\Users\\hoangvmdeptrai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\chromadb\\telemetry\\opentelemetry\\__init__.py:146\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[1;32m--> 146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\hoangvmdeptrai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\chromadb\\db\\mixins\\sysdb.py:229\u001b[0m, in \u001b[0;36mSqlSysDB.create_collection\u001b[1;34m(self, id, name, configuration, metadata, dimension, get_or_create, tenant, database)\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    223\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_collections(\n\u001b[0;32m    224\u001b[0m                 \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39mcollection[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m], tenant\u001b[38;5;241m=\u001b[39mtenant, database\u001b[38;5;241m=\u001b[39mdatabase\n\u001b[0;32m    225\u001b[0m             )[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    226\u001b[0m             \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    227\u001b[0m         )\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 229\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m UniqueConstraintError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCollection \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m already exists\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    231\u001b[0m collection \u001b[38;5;241m=\u001b[39m Collection(\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mid\u001b[39m,\n\u001b[0;32m    233\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    239\u001b[0m     version\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m    240\u001b[0m )\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtx() \u001b[38;5;28;01mas\u001b[39;00m cur:\n",
      "\u001b[1;31mUniqueConstraintError\u001b[0m: Collection microsoft-collection already exists"
     ]
    }
   ],
   "source": [
    "embedding_function = SentenceTransformerEmbeddingFunction()\n",
    "# print(embedding_function([token_split_texts[10]]))\n",
    "\n",
    "chroma_client = chromadb.Client()\n",
    "chroma_collection = chroma_client.create_collection(\n",
    "    \"microsoft-collection\", embedding_function=embedding_function\n",
    ")\n",
    "\n",
    "# extract the embeddings of the token_split_texts\n",
    "ids = [str(i) for i in range(len(token_split_texts))]\n",
    "chroma_collection.add(ids=ids, documents=token_split_texts)\n",
    "count = chroma_collection.count()\n",
    "print(count)\n",
    "query = \"What was the total revenue for the year?\"\n",
    "\n",
    "\n",
    "results = chroma_collection.query(query_texts=[query], n_results=5)\n",
    "retrieved_documents = results[\"documents\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup prompt and retriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hoangvmdeptrai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pydantic\\_migration.py:283: UserWarning: `pydantic.error_wrappers:ValidationError` has been moved to `pydantic:ValidationError`.\n",
      "  warnings.warn(f'`{import_path}` has been moved to `{new_location}`.')\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "Answer the question based on the context below and the conversation history. If you can't answer the question, reply \"I don't know\".\n",
    "When using information from the context, sources with the format [Citation X] must be included where X is the number of citation of each answer. \n",
    "If answer come from the same source, reuse the same citation number.  \n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Conversation History:\n",
    "{history}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "# splits = text_splitter.split_documents(pages)\n",
    "vectorstore = DocArrayInMemorySearch.from_documents(pages, embedding=embeddings)\n",
    "base_retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 5})\n",
    "\n",
    "# compressor = LLMChainExtractor.from_llm(model)\n",
    "# retriever = ContextualCompressionRetriever(\n",
    "#     base_compressor=compressor,\n",
    "#     base_retriever=base_retriever,\n",
    "# )\n",
    "retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 5})\n",
    "chain = prompt | model | parser\n",
    "\n",
    "chain.input_schema.schema()\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\") | retriever,\n",
    "        \"question\": itemgetter(\"question\"),\n",
    "        \"history\": itemgetter(\"history\"),\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    "    | parser\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversation Memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConversationMemory:\n",
    "  def __init__(self, max_history: int = 5):\n",
    "    self.history: List[Dict[str, str]] = []\n",
    "    self.max_history = max_history\n",
    "\n",
    "  def add_interaction(self, question: str, answer: str):\n",
    "    self.history.append({\"question\": question, \"answer\": answer})\n",
    "    if len(self.history) > self.max_history:\n",
    "      self.history.pop(0)\n",
    "\n",
    "  def get_formatted_history(self) -> str:\n",
    "    return \"\\n\".join(\n",
    "      [\n",
    "        f\"Human: {interaction['question']}\\nAI: {interaction['answer']}\"\n",
    "        for interaction in self.history\n",
    "      ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Response with Citations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response_with_citations(question: str, conversation_memory: ConversationMemory):\n",
    "    retrieved_docs = retriever.invoke(question)\n",
    "    context = \"\"\n",
    "    citations = []\n",
    "    for i, doc in enumerate(retrieved_docs):\n",
    "        relevant_text = doc.page_content\n",
    "        citation = create_citation(doc, relevant_text)\n",
    "        citations.append(citation)\n",
    "        context += f\"[Citation {i + 1}] {relevant_text}\\n\\n\"\n",
    "\n",
    "    history = conversation_memory.get_formatted_history()\n",
    "    response = chain.invoke({\"context\": context, \"question\": question, \"history\": history})\n",
    "\n",
    "    used_citations = []\n",
    "    for match in re.finditer(r\"\\[Citation (\\d+)\\]\", response):\n",
    "        citation_num = int(match.group(1))\n",
    "        if 1 <= citation_num <= len(citations):\n",
    "            used_citations.append(citations[citation_num - 1])\n",
    "\n",
    "    conversation_memory.add_interaction(question, response)\n",
    "    return response, used_citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_response_with_citations(response, citations):\n",
    "    formatted_response = f\"{response}\\n\\nCitations:\\n\"\n",
    "    if not citations:\n",
    "        formatted_response += \"No citations available.\\n\"\n",
    "    for i, citation in enumerate(citations):\n",
    "        try:\n",
    "            formatted_response += f\"{i+1}. Document: {citation['document_name']}, Page: {citation['page_number']}\\n\"\n",
    "            formatted_response += f\"   Text: {citation['text'][:100]}...\\n\\n\"\n",
    "        except Exception as e:\n",
    "            formatted_response += f\"{i+1}. Error formatting citation: {str(e)}\\n\\n\"\n",
    "    return formatted_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the purpose of .NET?\n",
      "According to the context, [Citation 1] provides information about what .NET is. The answer is:\n",
      "\n",
      "\"With .NET, you can use multiple languages, editors, and libraries to build applications for web, mobile, desktop, games, and IoT.\"\n",
      "\n",
      "This is from page 1 of the document, so I will cite it as [Citation 1].\n",
      "\n",
      "Citations:\n",
      "1. Document: dotnet.pdf, Page: 7\n",
      "   Text: 11/28/23, 9:58 AM .NET behind the scene. What is it .NET, How it works, and Why… | by Ofir Elarat | ...\n",
      "\n",
      "2. Document: dotnet.pdf, Page: 7\n",
      "   Text: 11/28/23, 9:58 AM .NET behind the scene. What is it .NET, How it works, and Why… | by Ofir Elarat | ...\n",
      "\n",
      "\n",
      "\n",
      "Question: What is the environment of .NET?\n",
      "According to the context, [Citation 2] provides information about the environment of .NET. The answer is:\n",
      "\n",
      "\"The .NET platform includes many different parts and a combination of them let you develop and run applications.\"\n",
      "\n",
      "[Citation 2]\n",
      "\n",
      "This is from page 1 of the document.\n",
      "\n",
      "Alternatively, another relevant answer can be found on page 6:\n",
      "\n",
      "\".NET’s garbage collector manages the allocation and release of memory for your application. Each time you create a new object, the CLR allocates memory for the object from the managed heap.\"\n",
      "\n",
      "[Citation 2]\n",
      "\n",
      "This is also related to the environment of .NET.\n",
      "\n",
      "I don't know if there's another relevant answer beyond this point.\n",
      "\n",
      "Citations:\n",
      "1. Document: dotnet.pdf, Page: 1\n",
      "   Text: 11/28/23, 9:58 AM .NET behind the scene. What is it .NET, How it works, and Why… | by Ofir Elarat | ...\n",
      "\n",
      "2. Document: dotnet.pdf, Page: 1\n",
      "   Text: 11/28/23, 9:58 AM .NET behind the scene. What is it .NET, How it works, and Why… | by Ofir Elarat | ...\n",
      "\n",
      "3. Document: dotnet.pdf, Page: 1\n",
      "   Text: 11/28/23, 9:58 AM .NET behind the scene. What is it .NET, How it works, and Why… | by Ofir Elarat | ...\n",
      "\n",
      "\n",
      "\n",
      "Question: How does .NET handle errors?\n",
      "According to the context, [Citation 4] provides information about how .NET handles errors. The answer is:\n",
      "\n",
      "\"Thanks to the JIT compiler, .NET platform can support easy error handling in your application code. When an error occurs, instead of terminate the process the CLR throw error event.\"\n",
      "\n",
      "[Citation 4]\n",
      "\n",
      "This is from page 10 of the document.\n",
      "\n",
      "Alternatively, another relevant answer can be found on page 6:\n",
      "\n",
      "\"In particular, the CLR throws error events when an error occurs, rather than terminating the process.\"\n",
      "\n",
      "[Citation 2]\n",
      "\n",
      "This is also related to how .NET handles errors.\n",
      "\n",
      "Citations:\n",
      "1. Document: dotnet.pdf, Page: 7\n",
      "   Text: 11/28/23, 9:58 AM .NET behind the scene. What is it .NET, How it works, and Why… | by Ofir Elarat | ...\n",
      "\n",
      "2. Document: dotnet.pdf, Page: 7\n",
      "   Text: 11/28/23, 9:58 AM .NET behind the scene. What is it .NET, How it works, and Why… | by Ofir Elarat | ...\n",
      "\n",
      "3. Document: dotnet.pdf, Page: 11\n",
      "   Text: 11/28/23, 9:58 AM .NET behind the scene. What is it .NET, How it works, and Why… | by Ofir Elarat | ...\n",
      "\n",
      "\n",
      "\n",
      "Question: Do you have information about DLL?\n",
      "According to the context, [Citation 5] provides information about DLL. The answer is:\n",
      "\n",
      "\"Unlike exe, DLL is not runnable because of one simple reason: every .NET executable file must have an entry point to start from, the main function. DLL doesn’t contain this function and therefore not runnable.\"\n",
      "\n",
      "[Citation 5]\n",
      "\n",
      "This is from page 9 of the document.\n",
      "\n",
      "Additionally, another relevant answer can be found on page 6:\n",
      "\n",
      "\"The computer cannot run the C# code directly and can only run native code. After we finish writing the app itself with C#, we can build the project to create an artifact using the C# compiler. The artifact we created (DLL or exe) contains CIL code, CIL is an intermediate language.\"\n",
      "\n",
      "[Citation 2]\n",
      "\n",
      "This also relates to DLL.\n",
      "\n",
      "I don't know if there's another relevant answer beyond this point.\n",
      "\n",
      "Citations:\n",
      "1. Document: dotnet.pdf, Page: 6\n",
      "   Text: 11/28/23, 9:58 AM .NET behind the scene. What is it .NET, How it works, and Why… | by Ofir Elarat | ...\n",
      "\n",
      "2. Document: dotnet.pdf, Page: 6\n",
      "   Text: 11/28/23, 9:58 AM .NET behind the scene. What is it .NET, How it works, and Why… | by Ofir Elarat | ...\n",
      "\n",
      "3. Document: dotnet.pdf, Page: 11\n",
      "   Text: 11/28/23, 9:58 AM .NET behind the scene. What is it .NET, How it works, and Why… | by Ofir Elarat | ...\n",
      "\n",
      "\n",
      "\n",
      "Question: What is the purpose of .NET?\n",
      "According to the context, [Citation 1] provides information about what .NET is. The answer is:\n",
      "\n",
      "\"With .NET, you can use multiple languages, editors, and libraries to build applications for web, mobile, desktop, games, and IoT.\"\n",
      "\n",
      "[Citation 1]\n",
      "\n",
      "This is from page 1 of the document.\n",
      "\n",
      "Citations:\n",
      "1. Document: dotnet.pdf, Page: 7\n",
      "   Text: 11/28/23, 9:58 AM .NET behind the scene. What is it .NET, How it works, and Why… | by Ofir Elarat | ...\n",
      "\n",
      "2. Document: dotnet.pdf, Page: 7\n",
      "   Text: 11/28/23, 9:58 AM .NET behind the scene. What is it .NET, How it works, and Why… | by Ofir Elarat | ...\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "questions = [\n",
    "    \"What is the purpose of .NET?\",\n",
    "    \"What is the environment of .NET?\",\n",
    "    \"How does .NET handle errors?\",\n",
    "    \"Do you have information about DLL?\",\n",
    "    \"What is the purpose of .NET?\",\n",
    "]\n",
    "conversation_memory = ConversationMemory()\n",
    "for question in questions:\n",
    "    print(f\"Question: {question}\")\n",
    "    response, citations = generate_response_with_citations(\n",
    "        question, conversation_memory\n",
    "    )\n",
    "    formatted_response = format_response_with_citations(response, citations)\n",
    "    print(formatted_response)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
